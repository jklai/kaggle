

;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[paths]

; Path to the training dataframe containing all the image data in pickle format
; e.g. df_path: '../data/roi/train_dataframe.pkl'
train_df_path: '../data/windows_20x20_center1px/stage1_train_dataframe.pkl'

; Path to the testing dataframe containing all the image data in pickle format
; e.g. df_path: '../data/roi/test_dataframe.pkl'
test_df_path: '../data/windows_20x20_center1px/stage1_test_dataframe.pkl'

; Path to the machine learning classifier in pickle format
; e.g. classifier_pkl: ../models/neural_network.pkl
classifier_pkl: '../models/svm_final_fixed_100percent.pkl'

; Path to directory where predictions are dumped; set to None to prevent output
; e.g. prediction_output_dir: '../data/predictions'
; e.g. prediction_output_dir: None
prediction_output_dir: '../data/predictions/submission_2' 

; Path to directory where all raw images are stored.
; e.g., raw_image_path:  '../data/raw/stage1_train'
raw_image_path: '../data/raw/stage1_train'


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[columns]

; Name of the column containing the image matrix/array
; e.g. image_col_name: image_matrix
image_col_name: 'image_matrix'

; Name of the column name used to categorize each entry (e.g. positive/negative)
; e.g. category_col_name: is_positive
category_col_name: 'is_positive'


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[specifications]

; Shape of the input image matrix
; e.g. fixed_size: ( 64, 64 )
fixed_size: ( 64, 64, 3 )


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[features]


; Feature extraction method
; e.g. feature_method: gkhp ; Gaussian kernel Hadamart product feature, requires a list of Gaussian kernel sigmas as extraction options
; e.g. feature_method: hog ; Histogram of gradients, requires options in a dict if none-default options is desired
; e.g. feature_method: pixelval ; extracting pixel values as features, no options needed (use None as input)
method: 'gkhp'

; Extraction options as dict (depends on the method)
; e.g. gkhp = feature_options: { 'sigmas': [ 1, 2, 4, 8, 16, 32, 64, 128 ] }
; e.g. hog = feature_options: { 'orientation': 9, 'pixels_per_cell': ( 8, 8 ), 'cells_per_block': ( 2, 2 ), 'block_norm': L2-Hys }
; e.g. pixelval = feature_options: {}
feature_options: { 'sigmas': [ 1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64, 128, 200 ] }

; Image processing options to preprocess the image before feature extraction
; e.g. image_processing_options: {'rgb2gray': True } ; converting rgb images into grayscale images
; e.g. image_processing_options: {'trim': [1, 99] } ; trimming off the top and bottom 1% pixel values
image_processing_options: { 'rgb2gray': None, 'trim': [1,99], 'norm': 'clahe' }
;image_processing_options: { 'rgb2gray': None, 'sobel': None }


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[svm] ; options for sklearn.svm

; Kernel to run with SVM (e.g. rbf, linear, poly, sigmoid)
; e.g. kernel: 'rbf'
kernel: 'rbf'

; Kernel coefficient (specify as auto if unsure)
; e.g. gamma: 'auto'
gamma: 0.03

; Penalty parameter (default is 1.0)
; e.g. C: 1.0
C: 10000000.0


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[tune] ; tuning options go here

; Turn on or off the tuning step
; e.g. tune_parameters: True
tune_parameters: False

; Parameters to be tuned and starting values
; e.g. parameters: [ { 'solver': ['adam'], 'alpha': [1e-3, 1e-4], 'hidden_layer_sizes': [ (50, 25), (100, 50), (200, 100) ] } ]
; e.g. parameters: [ { 'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10000] } ]
; e.g. parameters: { 'C': (1e-6, 1e+6, 'log-uniform'), 'gamma': (1e-6, 1e+1, 'log-uniform'), 'kernel': ['linear', 'poly', 'rbf'], }
;parameters: [ { 'solver': ['adam'], 'alpha': [1e-4], 'hidden_layer_sizes': [ (200,100),(256,128,64,32,16,8,4),(10,10,10,10,10,10,10),(200,100,50) ] } ]
;parameters: [ { 'solver': ['adam'], 'alpha': [1e-4], 'hidden_layer_sizes': [ (200,100,50),(200,100,50,25),(100,100,100),(128,64,32,16,8) ] } ]
;parameters: [ { 'solver': ['adam'], 'alpha': [1e-4], 'hidden_layer_sizes': [ (200,100),(100,100,100),(200,100,100),(100,100,100,100),(300,200,100) ] } ]
;parameters: [ { 'solver': ['adam'], 'alpha': [1e-4], 'hidden_layer_sizes': [ (200,100),(100,100,100),(200,100,50) ] } ]
parameters: [ { 'kernel': ['rbf'], 'gamma': [0.03, 0.01, 0.003], 'C': [3e5, 1e6, 3e6, 1e7] } ]

; Fraction of data to split for tuning (1.0 = full dataset)
; e.g. fraction: 0.1
fraction: 0.15

; Whether Bayes grid search is used, bool value True or False
; e.g. bayes: False
bayes: False

; Columns that should be diversified, can be set to None
; e.g. diversity_vars: [ 'parent_image_id' ]
diversity_vars: None

; Level of verbose for the tuning (e.g. 0, 10, 50)
; e.g. verbose: 50
verbose: 50

; Number of jobs to run in parallel (e.g. 1, 2, 4, 8)
; e.g. n_jobs: 4
n_jobs: 4

; Random seed of tuning optimization
; e.g. random_state: 1
random_state: 1


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[moving_window]

; NMS threshold
; e.g. nms_threshold: 0.5
nms_threshold: 0.5

; window size
; e.g. window_size: [64, 64]
window_size: [64, 64]

; step size
; e.g. step_size: [3, 3]
step_size: [1, 1]


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;

