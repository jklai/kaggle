

;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[paths]

; Path to the training dataframe containing all the image data in pickle format
; e.g. df_path: '../data/roi/train_dataframe.pkl'
train_df_path: '../data/roi/train_dataframe_center_3px.pkl'

; Path to the testing dataframe containing all the image data in pickle format
; e.g. df_path: '../data/roi/test_dataframe.pkl'
test_df_path: '../data/roi/test_dataframe_center_3px.pkl'

; Path to the machine learning classifier in pickle format
; e.g. classifier_pkl: ../models/neural_network.pkl
classifier_pkl: '../models/svm_gkhp_tuned_center3px_roi_graytrimnorm_halfdata.pkl'

; Path to directory where predictions are dumped; set to None to prevent output
; e.g. prediction_output_dir: '../data/predictions'
; e.g. prediction_output_dir: None
prediction_output_dir: '../data/roi/center3px/predictions'

; Path to directory where all raw images are stored.
; e.g., raw_image_path:  '../data/raw/stage1_train'
raw_image_path: '../data/raw/stage1_train'


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[columns]

; Name of the column containing the image matrix/array
; e.g. image_col_name: image_matrix
image_col_name: 'image_matrix'

; Name of the column name used to categorize each entry (e.g. positive/negative)
; e.g. category_col_name: is_positive
category_col_name: 'is_positive'


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[specifications]

; Shape of the input image matrix
; e.g. fixed_size: ( 64, 64 )
fixed_size: ( 64, 64, 3 )


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[features]


; Feature extraction method
; e.g. feature_method: gkhp ; Gaussian kernel Hadamart product feature, requires a list of Gaussian kernel sigmas as extraction options
; e.g. feature_method: hog ; Histogram of gradients, requires options in a dict if none-default options is desired
; e.g. feature_method: pixelval ; extracting pixel values as features, no options needed (use None as input)
method: 'gkhp'

; Extraction options as dict (depends on the method)
; e.g. gkhp = feature_options: { 'sigmas': [ 1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64, 128 ] }
; e.g. hog = feature_options: { 'orientation': 9, 'pixels_per_cell': ( 8, 8 ), 'cells_per_block': ( 2, 2 ), 'block_norm': L2-Hys }
; e.g. pixelval = feature_options: {}
feature_options: { 'sigmas': [ 1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64, 128, 200 ] }

; Image processing options to preprocess the image before feature extraction
; e.g. image_processing_options: {'rgb2gray': True } ; converting rgb images into grayscale images
; e.g. image_processing_options: {'trim': [1, 99] } ; trimming off the top and bottom 1% pixel values
image_processing_options: {'rgb2gray': None, 'trim': [1,99], 'norm': 'clahe'}


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[svm] ; options for sklearn.svm

; Kernel to run with SVM (e.g. rbf, linear, poly, sigmoid)
; e.g. kernel: 'rbf'
kernel: 'rbf'

; Kernel coefficient (specify as auto if unsure)
; e.g. gamma: 'auto'
gamma: 1

; Penalty parameter (default is 1.0)
; e.g. C: 1.0
C: 1000.0


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[mlp] ; options for sklearn.MLPClassifier

; Neural network solver (e.g. lbfgs, sgd, adam)
; e.g. solver: adam
solver: 'adam'

; L2 penalty, aka regularization (e.g. 0.0001, 0.00001, etc.)
; e.g. alpha: 0.0001
alpha: 0.0001

; Number of neurons in the ith hidden layer, e.g. (100,) or () or ()
; e.g. hidden_layer_sizes: ( 200, 100 )
hidden_layer_sizes: ( 200, 100 )

; Tolerance for teh MLPClassifier
; e.g. tol: 0.00001
tol: 1e-10

; Maximum number of iterations to run during MLP training
; e.g. max_iter: 200
max_iter: 500

; Random seed for the MLPClassifier
; e.g. random_state: 1
random_state: 1


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[tune] ; tuning options go here

; Turn on or off the tuning step
; e.g. tune_parameters: True
tune_parameters: True

; Parameters to be tuned and starting values
; e.g. parameters: [ { 'solver': ['adam'], 'alpha': [1e-3, 1e-4], 'hidden_layer_sizes': [ (50, 25), (100, 50), (200, 100) ] } ]
; e.g. parameters: [ { 'kernel': ['sigmoid'], 'gamma': [1e-3, 1e-4], 'C': [1, 10000] } ]
; e.g. parameters: { 'C': (1e-6, 1e+6, 'log-uniform'), 'gamma': (1e-6, 1e+1, 'log-uniform'), 'kernel': ['linear', 'poly', 'rbf'], }
parameters: [ { 'kernel': ['rbf'], 'gamma': [0.03, 0.01, 0.003, 0.001, 0.0003], 'C': [10000, 30000, 1e5, 3e5, 1e6] } ]

; Fraction of data to split for tuning (1.0 = full dataset)
; e.g. fraction: 0.1
fraction: 0.5

; Columns that should be diversified, can be set to None
; e.g. diversity_vars: [ 'parent_image_id' ]
diversity_vars: None

; Whether Bayes grid search is used, bool value True or False
; e.g. bayes: False
bayes: False

; Random seed of tuning optimization
; e.g. random_state: 1
random_state: 1

; Level of verbose for the tuning (e.g. 0, 10, 50)
; e.g. verbose: 50
verbose: 50

; Number of jobs to run in parallel (e.g. 1, 2, 4, 8)
; e.g. n_jobs: 4
n_jobs: 4


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;


[moving_window]

; NMS threshold
; e.g. nms_threshold: 0.5
nms_threshold: 0.5

; window size
; e.g. window_size: [64, 64]
window_size: [64, 64]

; step size
; e.g. step_size: [3, 3]
step_size: [3, 3]


;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;

